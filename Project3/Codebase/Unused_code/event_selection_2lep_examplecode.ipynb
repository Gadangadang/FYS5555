{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When running this notebook via the Galaxy portal\n",
    "You can access your data via the dataset number. Using a Python kernel, you can access dataset number 42 with ``handle = open(get(42), 'r')``.\n",
    "To save data, write your data to a file, and then call ``put('filename.txt')``. The dataset will then be available in your galaxy history.\n",
    "<br><br>Note that if you are putting/getting to/from a different history than your default history, you must also provide the history-id.\n",
    "<br><br>More information including available galaxy-related environment variables can be found at https://github.com/bgruening/docker-jupyter-notebook. This notebook is running in a docker container based on the Docker Jupyter container described in that link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ntuple to data frame conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook converts ntuples to pandas data frame and writes the output to hdf5 files. Events are selected when running over the ntuples and new variables are created and put into a data frame. Code adds the background category, whether the event is coming from a signal simulation or not (useful when training a BDT or NN) and the weight used to scale the MC to data.\n",
    "\n",
    "The current code takes about 4 - 5 hours on the simulated 2Lep background and signal samples. I.e. processing about 118 million events.\n",
    "\n",
    "First import some of the needed modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/02\n",
      "importing Jupyter notebook from setPath.ipynb\n",
      "importing Jupyter notebook from /storage/galaxy/jobs_directory/003/3139/working/jupyter/Input/OpenDataPandaFramework13TeV.ipynb\n",
      "This library contains handy functions to ease the access and use of the 13TeV ATLAS OpenData release\n",
      "\n",
      "getBkgCategories()\n",
      "\t Dumps the name of the various background cataegories available \n",
      "\t as well as the number of samples contained in each category.\n",
      "\t Returns a vector with the name of the categories\n",
      "\n",
      "getSamplesInCategory(cat)\n",
      "\t Dumps the name of the samples contained in a given category (cat)\n",
      "\t Returns dictionary with keys being DSIDs and values physics process name from filename.\n",
      "\n",
      "getMCCategory()\n",
      "\t Returns dictionary with keys DSID and values MC category\n",
      "\n",
      "initialize(indir)\n",
      "\t Collects all the root files available in a certain directory (indir)\n",
      "\n",
      "\n",
      "\n",
      "Setting luminosity to 10064 pb^-1\n",
      "\n",
      "###############################\n",
      "#### Background categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "Diboson                      10\n",
      "Higgs                        20\n",
      "Wjets                        42\n",
      "Wjetsincl                     6\n",
      "Zjets                        42\n",
      "Zjetsincl                     3\n",
      "singleTop                     6\n",
      "topX                          3\n",
      "ttbar                         1\n",
      "###############################\n",
      "#### Signal categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "GG_ttn1                       4\n",
      "Gee                           5\n",
      "Gmumu                         5\n",
      "RS_G_ZZ                       5\n",
      "SUSYC1C1                     10\n",
      "SUSYC1N2                     18\n",
      "SUSYSlepSlep                 14\n",
      "TT_directTT                   4\n",
      "ZPrimeee                      4\n",
      "ZPrimemumu                    4\n",
      "ZPrimett                     12\n",
      "dmV_Zll                      10\n"
     ]
    }
   ],
   "source": [
    "import ROOT as R\n",
    "import import_ipynb\n",
    "import setPath\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from Input.OpenDataPandaFramework13TeV import *\n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the open data ntuples and which skim you are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opendatadir = \"/storage/shared/data/fys5555/ATLAS_opendata/\"\n",
    "analysis = \"2lep\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the ROOT::TChain for adding all the root files and eventually looping over all the events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = R.TChain(\"mini\")\n",
    "data = R.TChain(\"mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the MC and data files available for the selected data set and make lists with the background and signal categories (useful information to add into the data frame later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "BACKGROUND SAMPLES\n",
      "####################################################################################################\n",
      "WARNING \t File for ggH125_tautaulh not found in /storage/shared/data/fys5555/ATLAS_opendata//2lep/MC\n",
      "WARNING \t File for VBFH125_tautaulh not found in /storage/shared/data/fys5555/ATLAS_opendata//2lep/MC\n",
      "####################################################################################################\n",
      "SIGNAL SAMPLES\n",
      "####################################################################################################\n",
      "WARNING \t File for ttH125_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//2lep/MC\n",
      "WARNING \t File for ggH125_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//2lep/MC\n",
      "WARNING \t File for VBFH125_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//2lep/MC\n",
      "WARNING \t File for WpH125J_Wincl_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//2lep/MC\n",
      "WARNING \t File for ZH125J_Zincl_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//2lep/MC\n",
      "WARNING \t File data.root not added as sample in Background_samples_13TeV.txt/Signal_samples_13TeV.txt\n",
      "###############################\n",
      "#### Background categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "Diboson                      10\n",
      "Higgs                        20\n",
      "Wjets                        42\n",
      "Wjetsincl                     6\n",
      "Zjets                        42\n",
      "Zjetsincl                     3\n",
      "singleTop                     6\n",
      "topX                          3\n",
      "ttbar                         1\n",
      "###############################\n",
      "#### Signal categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "GG_ttn1                       4\n",
      "Gee                           5\n",
      "Gmumu                         5\n",
      "RS_G_ZZ                       5\n",
      "SUSYC1C1                     10\n",
      "SUSYC1N2                     18\n",
      "SUSYSlepSlep                 14\n",
      "TT_directTT                   4\n",
      "ZPrimeee                      4\n",
      "ZPrimemumu                    4\n",
      "ZPrimett                     12\n",
      "dmV_Zll                      10\n"
     ]
    }
   ],
   "source": [
    "mcfiles = initialize(opendatadir+\"/\"+analysis+\"/MC\")\n",
    "datafiles = initialize(opendatadir+\"/\"+analysis+\"/Data\")\n",
    "allfiles = z = {**mcfiles, **datafiles}\n",
    "Backgrounds = getBkgCategories(); \n",
    "Signals = getSignalCategories();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more preparatory steps to classify the individual backgrounds into categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "#### Signal categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "GG_ttn1                       4\n",
      "Gee                           5\n",
      "Gmumu                         5\n",
      "RS_G_ZZ                       5\n",
      "SUSYC1C1                     10\n",
      "SUSYC1N2                     18\n",
      "SUSYSlepSlep                 14\n",
      "TT_directTT                   4\n",
      "ZPrimeee                      4\n",
      "ZPrimemumu                    4\n",
      "ZPrimett                     12\n",
      "dmV_Zll                      10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GG_ttn1',\n",
       " 'Gee',\n",
       " 'Gmumu',\n",
       " 'RS_G_ZZ',\n",
       " 'SUSYC1C1',\n",
       " 'SUSYC1N2',\n",
       " 'SUSYSlepSlep',\n",
       " 'TT_directTT',\n",
       " 'ZPrimeee',\n",
       " 'ZPrimemumu',\n",
       " 'ZPrimett',\n",
       " 'dmV_Zll']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSignalCategories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCcat = {}\n",
    "for cat in allfiles:\n",
    "    for dsid in allfiles[cat][\"dsid\"]:\n",
    "        try:\n",
    "            MCcat[int(dsid)] = cat\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the background to the TChain and check number of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 121180468 entries for backgrounds\n"
     ]
    }
   ],
   "source": [
    "dataset_IDs = []\n",
    "background.Reset()\n",
    "for b in Backgrounds+Signals:\n",
    "    i = 0\n",
    "    if not b in mcfiles.keys(): continue\n",
    "    for mc in mcfiles[b][\"files\"]:\n",
    "        if not os.path.isfile(mc): continue\n",
    "        try:\n",
    "            dataset_IDs.append(int(mcfiles[b][\"dsid\"][i]))\n",
    "            background.Add(mc)\n",
    "        except:\n",
    "            print(\"Could not get DSID for %s. Skipping\"%mc)\n",
    "        i += 1\n",
    "nen = background.GetEntries()\n",
    "print(\"Added %i entries for backgrounds\"%(nen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding all the available data into the TChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 24411580 entries for data\n"
     ]
    }
   ],
   "source": [
    "data.Reset(); \n",
    "for d in datafiles[\"data\"][\"files\"]:  \n",
    "    if not os.path.isfile(d): continue\n",
    "    data.Add(d)\n",
    "nen = data.GetEntries()\n",
    "print(\"Added %i entries for data\"%(nen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the variables/features we want to add to our data frame and which will be filled during the loop over events. Here you can add and remove variables depending on what you will use the resulting data frame to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\"lep_pt1\":[],\"lep_eta1\":[],\"lep_phi1\":[],\"lep_E1\":[],\n",
    "           \"lep_pt2\":[],\"lep_eta2\":[],\"lep_phi2\":[],\"lep_E2\":[],\n",
    "           \"met\":[], \"mll\":[], \"njet20\":[], \"njet60\":[], \"nbjet80\":[],\n",
    "           \"isSF\":[], \"isOS\":[], \"weight\":[],\"category\":[],\"isSignal\":[],\n",
    "           \"lep_z0_1\":[], \"lep_z0_2\":[], \"lep_trackd0pvunbiased_1\":[],\n",
    "           \"lep_trackd0pvunbiased_2\":[], \"lep_tracksigd0pvunbiased_1\":[], \"lep_tracksigd0pvunbiased_2\":[],\n",
    "           \"met_phi\":[], \"lep_pt_syst_1\":[], \"lep_pt_syst_2\":[], \"met_et_syst\":[], \"lep_etcone20_1\":[],  \n",
    "           \"lep_etcone20_2\":[], \"lep_ptcone30_1\":[], \"lep_ptcone30_2\":[]\n",
    "           \n",
    "           \n",
    "          \n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the event loop (needs to be run twice; one for MC and one for data if you are interested in both). It makes some selections, creates new variables and fill the list in the dictionary defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Remebered to run over data? No? Set data = 1 at the top and run again\n",
      "CPU times: user 2.86 ms, sys: 0 ns, total: 2.86 ms\n",
      "Wall time: 2.85 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "isData = 0; \n",
    "\n",
    "if isData == 1: ds = data \n",
    "else: ds = background     \n",
    "\n",
    "l1 = R.TLorentzVector() \n",
    "l2 = R.TLorentzVector() \n",
    "dileptons = R.TLorentzVector() \n",
    "    \n",
    "i = 0   \n",
    "for event in ds: \n",
    "    \n",
    "    if i%100000 == 0 and i>0: \n",
    "        print(\"Total events %i/%i\"%(i,ds.GetEntries()))\n",
    "        #break\n",
    "    i += 1 \n",
    "    \n",
    "    sig_lep_idx = []\n",
    "    nsig_lep = 0\n",
    "    for j in range(ds.lep_n):\n",
    "        if ds.lep_etcone20[j]/ds.lep_pt[j] > 0.15: continue\n",
    "        if ds.lep_ptcone30[j]/ds.lep_pt[j] > 0.15: continue\n",
    "        sig_lep_idx.append(j)\n",
    "        nsig_lep += 1\n",
    "        \n",
    "    if not nsig_lep == 2: continue \n",
    "    njet20 = 0\n",
    "    njet60 = 0\n",
    "    nbjet60 = 0\n",
    "    nbjet70 = 0\n",
    "    nbjet77 = 0\n",
    "    nbjet80 = 0\n",
    "    for j in range(ds.jet_n):\n",
    "        if ds.jet_pt[j] > 20000:\n",
    "            njet20 += 1\n",
    "            if ds.jet_MV2c10[j] < 0.1758:\n",
    "                nbjet80 += 1\n",
    "        if ds.jet_pt[j] > 60000:\n",
    "            njet60 += 1\n",
    "        \n",
    "    ## Require \"good leptons\": \n",
    "    idx1 = sig_lep_idx[0]\n",
    "    idx2 = sig_lep_idx[1]\n",
    "    \n",
    "    ## Set Lorentz vectors: \n",
    "    l1.SetPtEtaPhiE(ds.lep_pt[idx1]/1000., ds.lep_eta[idx1], ds.lep_phi[idx1], ds.lep_E[idx1]/1000.);\n",
    "    l2.SetPtEtaPhiE(ds.lep_pt[idx2]/1000., ds.lep_eta[idx2], ds.lep_phi[idx2], ds.lep_E[idx2]/1000.);\n",
    "    ## Variables are stored in the TTree with unit MeV, so we need to divide by 1000 \n",
    "    ## to get GeV, which is a more practical and commonly used unit. \n",
    "\n",
    "    dileptons = l1 + l2;   \n",
    "    \n",
    "    columns[\"lep_pt1\"].append(ds.lep_pt[idx1]/1000.0)\n",
    "    columns[\"lep_eta1\"].append(ds.lep_eta[idx1])\n",
    "    columns[\"lep_phi1\"].append(ds.lep_phi[idx1])\n",
    "    columns[\"lep_E1\"].append(ds.lep_E[idx1]/1000.0)\n",
    "    \n",
    "    columns[\"lep_pt2\"].append(ds.lep_pt[idx2]/1000.0)\n",
    "    columns[\"lep_eta2\"].append(ds.lep_eta[idx2])\n",
    "    columns[\"lep_phi2\"].append(ds.lep_phi[idx2])\n",
    "    columns[\"lep_E2\"].append(ds.lep_E[idx2]/1000.0)\n",
    "    \n",
    "    columns[\"met\"].append(ds.met_et/1000.0)\n",
    "    columns[\"mll\"].append(dileptons.M())\n",
    "    \n",
    "    columns[\"njet20\"].append(njet20)\n",
    "    columns[\"njet60\"].append(njet60)\n",
    "    \n",
    " \n",
    "    columns[\"nbjet80\"].append(nbjet80)\n",
    "    \n",
    "    if not isData:\n",
    "        Type = MCcat[ds.channelNumber]\n",
    "        # print(\"Type\",Type)\n",
    "        columns[\"category\"].append(Type)\n",
    "    else:\n",
    "        columns[\"category\"].append(\"data\")\n",
    "    \n",
    "        \n",
    "    if Type in Backgrounds:\n",
    "        columns[\"isSignal\"].append(0)\n",
    "    elif Type in Signals:\n",
    "        columns[\"isSignal\"].append(1)\n",
    "    else:\n",
    "        columns[\"isSignal\"].append(0)\n",
    "    \n",
    "    if ds.lep_charge[idx1] == ds.lep_charge[idx2]: columns[\"isOS\"].append(0)\n",
    "    else: columns[\"isOS\"].append(1)\n",
    "        \n",
    "    if ds.lep_type[idx1] == ds.lep_type[idx2]: columns[\"isSF\"].append(1)\n",
    "    else: columns[\"isSF\"].append(0)\n",
    "        \n",
    "    if isData:\n",
    "        columns[\"weight\"].append(1.0)\n",
    "    else:\n",
    "        W = ((ds.mcWeight)*(ds.scaleFactor_PILEUP)*\n",
    "             (ds.scaleFactor_ELE)*(ds.scaleFactor_MUON)*\n",
    "             (ds.scaleFactor_BTAG)*(ds.scaleFactor_LepTRIGGER))*((ds.XSection*lumi)/ds.SumWeights)\n",
    "        columns[\"weight\"].append(W)\n",
    "   \n",
    "        \n",
    "  \n",
    "    columns[\"lep_z0_1\"].append(ds.lep_z0[idx1])\n",
    "    columns[\"lep_z0_2\"].append(ds.lep_z0[idx2])\n",
    "    \n",
    "    columns[\"lep_trackd0pvunbiased_1\"].append(ds.lep_trackd0pvunbiased[idx1])\n",
    "    columns[\"lep_trackd0pvunbiased_2\"].append(ds.lep_trackd0pvunbiased[idx2])\n",
    "    \n",
    "    columns[\"lep_tracksigd0pvunbiased_1\"].append(ds.lep_tracksigd0pvunbiased[idx1])\n",
    "    columns[\"lep_tracksigd0pvunbiased_2\"].append(ds.lep_tracksigd0pvunbiased[idx2])\n",
    "    \n",
    "    columns[\"met_phi\"].append(ds.met_phi)\n",
    "    \n",
    "    columns[\"lep_pt_syst_1\"].append(ds.lep_pt_syst[idx1])\n",
    "    columns[\"lep_pt_syst_2\"].append(ds.lep_pt_syst[idx2])\n",
    "    \n",
    "    columns[\"met_et_syst\"].append(ds.met_et_syst)\n",
    "    \n",
    "    columns[\"lep_etcone20_1\"].append(ds.lep_etcone20[idx1]/ds.lep_pt[idx1] )\n",
    "    columns[\"lep_etcone20_2\"].append(ds.lep_etcone20[idx2]/ds.lep_pt[idx2])\n",
    "                                    \n",
    "    columns[\"lep_ptcone30_1\"].append(ds.lep_etcone20[idx1]/ds.lep_pt[idx1] )\n",
    "    columns[\"lep_ptcone30_2\"].append(ds.lep_etcone20[idx2]/ds.lep_pt[idx2])\n",
    "\n",
    "        \n",
    "print(\"Done!\")\n",
    "if isData == 0:\n",
    "    print(\"Remebered to run over data? No? Set data = 1 at the top and run again\")\n",
    "else:\n",
    "    print(\"Remebered to run over MC? No? Set data = 0 at the top and run again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally convert the dictionary to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lep_pt1  lep_eta1  lep_phi1      lep_E1    lep_pt2  lep_eta2  lep_phi2  \\\n",
      "0   124.174242  0.874867  1.808438  174.804609  36.407164 -0.088034  2.809092   \n",
      "1    81.009211 -0.172663  2.475907   82.219758  49.662348  0.419312  1.085146   \n",
      "2    71.252680 -0.190694  2.687513   72.552219  34.968070 -1.183697 -2.000721   \n",
      "3    52.469828  0.626280 -3.089676   63.100617  42.395828  0.286550 -0.852670   \n",
      "4    61.642246 -0.359743 -0.503622   65.674258  31.970502 -1.249790  1.979540   \n",
      "5    44.796750  2.258051 -2.900190  216.569531  23.854400  0.491639  0.989600   \n",
      "6    50.000758  2.364431 -1.107304  268.303844  37.587879  1.913280  1.915223   \n",
      "7    83.771773  1.829904 -1.813111  267.806469  30.891246  2.213547  2.053218   \n",
      "8    61.179313  0.665834 -2.552287   75.249344  37.775004  0.687066 -0.124923   \n",
      "9    45.091684 -1.007820 -1.399480   69.996703  37.807648  0.652300 -0.048723   \n",
      "10   52.586027 -0.258767  0.366813   54.356461  45.281090  0.417318  2.399606   \n",
      "\n",
      "        lep_E2        met        mll  ...  lep_tracksigd0pvunbiased_1  \\\n",
      "0    36.548332  26.631432  93.204437  ...                    1.083617   \n",
      "1    54.092566  29.575090  89.760332  ...                    1.196993   \n",
      "2    62.463102  24.493008  88.141915  ...                    1.250408   \n",
      "3    44.148352  12.226987  86.358315  ...                    0.757241   \n",
      "4    60.363176  32.936660  93.413226  ...                    0.985643   \n",
      "5    26.796061   9.042903  89.444350  ...                    0.055971   \n",
      "6   130.108086  44.858078  88.770372  ...                    1.297810   \n",
      "7   142.986547  16.788213  97.139394  ...                    2.021680   \n",
      "8    47.047449  35.921730  90.086843  ...                    2.000210   \n",
      "9    46.140535  10.301906  92.450805  ...                    0.020363   \n",
      "10   49.281605  11.010781  89.529539  ...                    0.903672   \n",
      "\n",
      "    lep_tracksigd0pvunbiased_2   met_phi  lep_pt_syst_1  lep_pt_syst_2  \\\n",
      "0                     0.015223 -1.100751     907.409912     118.700920   \n",
      "1                     0.348870 -1.172956     758.927734      38.109222   \n",
      "2                     2.277764 -3.103178    1162.273682     485.886230   \n",
      "3                     1.240821  1.663237      56.704197      42.385590   \n",
      "4                     0.913827 -0.324797     323.474426     179.437439   \n",
      "5                     2.470215 -0.306070     713.084106     148.593567   \n",
      "6                     1.948602  0.046542    1003.957642     330.816895   \n",
      "7                     1.192623 -1.845685     605.640564     255.120819   \n",
      "8                     4.277082 -2.602130     585.495911      51.242008   \n",
      "9                     0.628943  1.405834     140.105728     225.041061   \n",
      "10                    1.983894 -2.540044      77.348999      23.855352   \n",
      "\n",
      "     met_et_syst lep_etcone20_1  lep_etcone20_2  lep_ptcone30_1  \\\n",
      "0    1425.666016      -0.000771        0.057770       -0.000771   \n",
      "1    3258.632812       0.024593        0.009449        0.024593   \n",
      "2   50237.960938       0.013963        0.004990        0.013963   \n",
      "3    1185.458008       0.003700       -0.008542        0.003700   \n",
      "4    3189.679688      -0.001935        0.003292       -0.001935   \n",
      "5    4783.271973      -0.003588        0.040688       -0.003588   \n",
      "6     474.535156      -0.003968       -0.008891       -0.003968   \n",
      "7    8209.476562      -0.007525       -0.008829       -0.007525   \n",
      "8    2273.914062      -0.019254       -0.024537       -0.019254   \n",
      "9     400.652344      -0.013423       -0.003929       -0.013423   \n",
      "10   1029.280273       0.020894       -0.001205        0.020894   \n",
      "\n",
      "    lep_ptcone30_2  \n",
      "0         0.057770  \n",
      "1         0.009449  \n",
      "2         0.004990  \n",
      "3        -0.008542  \n",
      "4         0.003292  \n",
      "5         0.040688  \n",
      "6        -0.008891  \n",
      "7        -0.008829  \n",
      "8        -0.024537  \n",
      "9        -0.003929  \n",
      "10       -0.001205  \n",
      "\n",
      "[11 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and write it to a file for later use. There are many more possibilites for file format. Have a look at the pandas documentation (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html) for possibilites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(\"/storage/shared/data/2lep_df_forML_signal.hdf5\",\"mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(\"/storage/shared/data/2lep_df_forML.hdf5\",\"mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nbjet60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reread = pd.read_hdf(\"/storage/shared/data/2lep_df_forML.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
