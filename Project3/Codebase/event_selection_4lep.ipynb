{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When running this notebook via the Galaxy portal\n",
    "You can access your data via the dataset number. Using a Python kernel, you can access dataset number 42 with ``handle = open(get(42), 'r')``.\n",
    "To save data, write your data to a file, and then call ``put('filename.txt')``. The dataset will then be available in your galaxy history.\n",
    "<br><br>Note that if you are putting/getting to/from a different history than your default history, you must also provide the history-id.\n",
    "<br><br>More information including available galaxy-related environment variables can be found at https://github.com/bgruening/docker-jupyter-notebook. This notebook is running in a docker container based on the Docker Jupyter container described in that link.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling (Python) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/02\n",
      "importing Jupyter notebook from setPath.ipynb\n",
      "importing Jupyter notebook from /storage/galaxy/jobs_directory/003/3028/working/jupyter/Input/OpenDataPandaFramework13TeV.ipynb\n",
      "This library contains handy functions to ease the access and use of the 13TeV ATLAS OpenData release\n",
      "\n",
      "getBkgCategories()\n",
      "\t Dumps the name of the various background cataegories available \n",
      "\t as well as the number of samples contained in each category.\n",
      "\t Returns a vector with the name of the categories\n",
      "\n",
      "getSamplesInCategory(cat)\n",
      "\t Dumps the name of the samples contained in a given category (cat)\n",
      "\t Returns dictionary with keys being DSIDs and values physics process name from filename.\n",
      "\n",
      "getMCCategory()\n",
      "\t Returns dictionary with keys DSID and values MC category\n",
      "\n",
      "initialize(indir)\n",
      "\t Collects all the root files available in a certain directory (indir)\n",
      "\n",
      "\n",
      "\n",
      "Setting luminosity to 10064 pb^-1\n",
      "\n",
      "###############################\n",
      "#### Background categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "Diboson                      10\n",
      "Higgs                        20\n",
      "Wjets                        42\n",
      "Wjetsincl                     6\n",
      "Zjets                        42\n",
      "Zjetsincl                     3\n",
      "singleTop                     6\n",
      "topX                          3\n",
      "ttbar                         1\n",
      "###############################\n",
      "#### Signal categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "GG_ttn1                       4\n",
      "Gee                           5\n",
      "Gmumu                         5\n",
      "RS_G_ZZ                       5\n",
      "SUSYC1C1                     10\n",
      "SUSYC1N2                     18\n",
      "SUSYSlepSlep                 14\n",
      "TT_directTT                   4\n",
      "ZPrimeee                      4\n",
      "ZPrimemumu                    4\n",
      "ZPrimett                     12\n",
      "dmV_Zll                      10\n"
     ]
    }
   ],
   "source": [
    "import ROOT as R\n",
    "import import_ipynb\n",
    "import setPath\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from Input.OpenDataPandaFramework13TeV import *\n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the analaysis to run (*1largeRjet1lep*, *1lep1tau*, *3lep*, *exactly2lep*, *GamGam*, *2lep*, *4lep*)\n",
    "\n",
    "Set the directory where you have downloaded the ATLAS OpenData samples you want to run over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opendatadir = \"/storage/shared/data/fys5555/ATLAS_opendata/\"\n",
    "analysis = \"4lep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = R.TChain(\"mini\")\n",
    "data = R.TChain(\"mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all the background samples, category and their IDs can be found in **Infofile.txt**. The cross-section, efficiencies etc. needed for scaling are stored in the **Files_<---->**. We read these files and add all the samples to the TChain. We also (for later convenience) make a vector containing the dataset IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "BACKGROUND SAMPLES\n",
      "####################################################################################################\n",
      "WARNING \t File for Ztautau_PTV1000_E_CMS not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV0_70_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV500_1000 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV1000_E_CMS not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV0_70_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV70_140_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV500_1000 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV1000_E_CMS not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV0_70_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV500_1000 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV1000_E_CMS not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV0_70_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV0_70_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV70_140_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV70_140_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV70_140_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV140_280_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV140_280_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV140_280_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV280_500_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV280_500_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wmunu_PTV280_500_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV0_70_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV0_70_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV70_140_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV70_140_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV140_280_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV140_280_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV140_280_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV280_500_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV280_500_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wenu_PTV280_500_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV0_70_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV0_70_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV70_140_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV70_140_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV70_140_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV140_280_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV140_280_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV140_280_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV280_500_CVetoBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV280_500_CFilterBVeto not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Wtaunu_PTV280_500_BFilter not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ggH125_tautaulh not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for VBFH125_tautaulh not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "####################################################################################################\n",
      "SIGNAL SAMPLES\n",
      "####################################################################################################\n",
      "WARNING \t File for SlepSlep_direct_200p5_1p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_100p5_1p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_500p5_1p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_300p5_1p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_100p0_50p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_500p0_100p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_200p0_100p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_300p0_200p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_400p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_500p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_600p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_600p0_1p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_700p0_1p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for SlepSlep_direct_700p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_300p0_100p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_200p0_150p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_200p0_100p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_400p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_400p0_100p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_300p0_250p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_600p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_500p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_700p0_1p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1C1_SlepSnu_x0p50_700p0_300p0_2L8 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_350p0_0p0_3L_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_400p0_0p0_3L_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_100p0_0p0_3L_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_500p0_0p0_3L_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_500p0_100p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_300p0_200p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_300p0_100p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_500p0_0p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_400p0_0p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_100p0_0p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_400p0_300p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_600_100_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_500p0_300p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_200p0_100p0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_700_0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_700_100_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_700_400_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for C1N2_WZ_600_0_2L2J_2L7 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime5000_ee not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime4000_ee not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime4000_mumu not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime750_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime5000_mumu not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime2000_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime1750_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime1500_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime1250_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime1000_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime3000_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime2750_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime2500_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZPrime2250_tt not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM10 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM100 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM2000 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM300 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM700 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM500 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM600 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM400 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM200 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for dmV_Zll_MET40_DM1_MM800 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Gee_01_750 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for Gmumu_01_750 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for TT_directTT_500_1 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for TT_directTT_500_200 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for TT_directTT_600_1 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for TT_directTT_450_1 not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ttH125_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ggH125_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for VBFH125_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for WpH125J_Wincl_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "WARNING \t File for ZH125J_Zincl_gamgam not found in /storage/shared/data/fys5555/ATLAS_opendata//4lep/MC\n",
      "###############################\n",
      "#### Background categories ####\n",
      "###############################\n",
      "Category             N(samples)\n",
      "-------------------------------\n",
      "Diboson                      10\n",
      "Higgs                        20\n",
      "Wjets                        42\n",
      "Wjetsincl                     6\n",
      "Zjets                        42\n",
      "Zjetsincl                     3\n",
      "singleTop                     6\n",
      "topX                          3\n",
      "ttbar                         1\n"
     ]
    }
   ],
   "source": [
    "mcfiles = initialize(opendatadir+\"/\"+analysis+\"/MC\")\n",
    "datafiles = initialize(opendatadir+\"/\"+analysis+\"/Data\")\n",
    "allfiles = z = {**mcfiles, **datafiles}\n",
    "Backgrounds = getBkgCategories() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCcat = {}\n",
    "for cat in allfiles:\n",
    "    for dsid in allfiles[cat][\"dsid\"]:\n",
    "        try:\n",
    "            MCcat[int(dsid)] = cat\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1601489 entries for backgrounds\n"
     ]
    }
   ],
   "source": [
    "dataset_IDs = []\n",
    "background.Reset()\n",
    "for b in Backgrounds:\n",
    "    i = 0\n",
    "    if not b in mcfiles.keys(): continue\n",
    "    for mc in mcfiles[b][\"files\"]:\n",
    "        if not os.path.isfile(mc): continue\n",
    "        try:\n",
    "            dataset_IDs.append(int(mcfiles[b][\"dsid\"][i]))\n",
    "            background.Add(mc)\n",
    "        except:\n",
    "            print(\"Could not get DSID for %s. Skipping\"%mc)\n",
    "        i += 1\n",
    "nen = background.GetEntries()\n",
    "print(\"Added %i entries for backgrounds\"%(nen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 832 entries for backgrounds\n"
     ]
    }
   ],
   "source": [
    "data.Reset(); \n",
    "for d in datafiles[\"data\"][\"files\"]:  \n",
    "    if not os.path.isfile(d): continue\n",
    "    data.Add(d)\n",
    "nen = data.GetEntries()\n",
    "print(\"Added %i entries for backgrounds\"%(nen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making (a lot of) histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read our dataset we want to start analyzing the data. To do so we need to put the data into histograms. For reasons that will become clear later in the analysis we must (for each variable) make one histogram per dataset ID. (We have 31 background samples, so if we want to study 10 variables we have to make 310 histograms!) For best dealing with all these histograms we can use dictionaries (Python) or maps (C++). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data it is only necessary with one histogram for each variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias lumi\n"
     ]
    }
   ],
   "source": [
    "# Retrieve lumi from library\n",
    "%store -r lumi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the cell where the analysis is performed. Note that the cell needs to be run twice:\n",
    "\n",
    "1. with data = 0 to run over MC\n",
    "2. with data = 1 to run over data\n",
    "\n",
    "Note that the MC running takes ~5 minutes for 3lep analysis. Much(!!!) more time for e.g. 2lep analysis! Data running is relatively fast for 3lep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events 100000/1601489\n",
      "Done!\n",
      "Remebered to run over data? No? Set data = 1 at the top and run again\n",
      "CPU times: user 20.1 s, sys: 198 ms, total: 20.3 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "isData = 0; \n",
    "\n",
    "if isData == 1: ds = data \n",
    "else: ds = background\n",
    "\n",
    "legal_flavor_tot = [13*4, 11*4, 11*2 + 13*2]\n",
    "    \n",
    "columns = {\"lep_pt1\":[],\"lep_eta1\":[],\"lep_phi1\":[],\"lep_E1\":[],\n",
    "           \"lep_pt2\":[],\"lep_eta2\":[],\"lep_phi2\":[],\"lep_E2\":[],\n",
    "           \"lep_pt3\":[],\"lep_eta3\":[],\"lep_phi3\":[],\"lep_E3\":[],\n",
    "           \"lep_pt4\":[],\"lep_eta4\":[],\"lep_phi4\":[],\"lep_E4\":[],\n",
    "           \"met\":[]}\n",
    "\n",
    "i = 0   \n",
    "for event in ds: \n",
    "    \n",
    "    if i%100000 == 0 and i>0: \n",
    "        print(\"Total events %i/%i\"%(i,ds.GetEntries()))\n",
    "    i += 1 \n",
    "    ## Data quality cuts: \n",
    "    \n",
    "    #if i > 10000: break\n",
    "    \n",
    "    #if ds.passGRL == 0: continue\n",
    "    #if ds.hasGoodVertex == 0: continue\n",
    "    #if(trigM == 0 && trigE == 0){ continue; } \n",
    "\n",
    "    \n",
    "    \n",
    "    ## Cut #1: Require (exactly) 2 leptons\n",
    "    if not ds.lep_n == 4: continue\n",
    "    ## Cut #2: Require opposite charge\n",
    "    if not ds.lep_charge[0] + ds.lep_charge[1] + ds.lep_charge[2] + ds.lep_charge[3] == 0 : continue\n",
    "    ## Cut #3: Require same flavour (2 electrons or 2 muons)\n",
    "    if not ds.lep_type[0] + ds.lep_type[1] + ds.lep_type[2] + ds.lep_type[3] in legal_flavor_tot: continue\n",
    "\n",
    "    \n",
    "    ## Require \"good leptons\": \n",
    "    \n",
    "    if ds.lep_pt[0]/1000.0 < 25: continue\n",
    "    if ds.lep_etcone20[0]/ds.lep_pt[0] > 0.15: continue\n",
    "    if ds.lep_ptcone30[0]/ds.lep_pt[0] > 0.15: continue\n",
    "    #if not (ds.lep_flag[0] & 512): continue\n",
    "        \n",
    "    if ds.lep_pt[1]/1000.0 < 25: continue\n",
    "    if ds.lep_etcone20[1]/ds.lep_pt[1] > 0.15: continue\n",
    "    if ds.lep_ptcone30[1]/ds.lep_pt[1] > 0.15: continue\n",
    "    #if not (ds.lep_flag[1] & 512): continue\n",
    "    \n",
    "    if ds.lep_etcone20[2]/ds.lep_pt[2] > 0.3: continue\n",
    "    if ds.lep_ptcone30[2]/ds.lep_pt[2] > 0.3: continue\n",
    "    #if not (ds.lep_flag[0] & 512): continue\n",
    "        \n",
    "    \n",
    "    if ds.lep_etcone20[3]/ds.lep_pt[3] > 0.3: continue\n",
    "    if ds.lep_ptcone30[3]/ds.lep_pt[3] > 0.3: continue\n",
    "    \n",
    "    ## Event selection:\n",
    "    columns[\"lep_pt1\"].append(ds.lep_pt[0]/1000.0)\n",
    "    columns[\"lep_eta1\"].append(ds.lep_eta[0])\n",
    "    columns[\"lep_phi1\"].append(ds.lep_phi[0])\n",
    "    columns[\"lep_E1\"].append(ds.lep_E[0]/1000.0)\n",
    "    \n",
    "    columns[\"lep_pt2\"].append(ds.lep_pt[1]/1000.0)\n",
    "    columns[\"lep_eta2\"].append(ds.lep_eta[1])\n",
    "    columns[\"lep_phi2\"].append(ds.lep_phi[1])\n",
    "    columns[\"lep_E2\"].append(ds.lep_E[1]/1000.0)\n",
    "    \n",
    "    columns[\"lep_pt3\"].append(ds.lep_pt[2]/1000.0)\n",
    "    columns[\"lep_eta3\"].append(ds.lep_eta[2])\n",
    "    columns[\"lep_phi3\"].append(ds.lep_phi[2])\n",
    "    columns[\"lep_E3\"].append(ds.lep_E[2]/1000.0)\n",
    "    \n",
    "    columns[\"lep_pt4\"].append(ds.lep_pt[3]/1000.0)\n",
    "    columns[\"lep_eta4\"].append(ds.lep_eta[3])\n",
    "    columns[\"lep_phi4\"].append(ds.lep_phi[3])\n",
    "    columns[\"lep_E4\"].append(ds.lep_E[3]/1000.0)\n",
    "    \n",
    "    columns[\"met\"].append(ds.met_et/1000.0)\n",
    "    \n",
    "    if i%200000 == 0 and i>0:\n",
    "        break\n",
    "    \n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data=columns)\n",
    "        \n",
    "print(\"Done!\")\n",
    "if isData == 0:\n",
    "    print(\"Remebered to run over data? No? Set data = 1 at the top and run again\")\n",
    "else:\n",
    "    print(\"Remebered to run over MC? No? Set data = 0 at the top and run again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(\"datatest.hdf5\",\"mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
