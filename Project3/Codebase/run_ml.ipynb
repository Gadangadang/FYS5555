{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-alfred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alert-sound",
   "metadata": {},
   "source": [
    "# ML test\n",
    "### Testing of reading in data and trying an auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baking-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "seed = tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vertical-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"/storage/shared/data/2lep_df_forML.hdf5\")\n",
    "df = pd.concat([df,pd.read_hdf(\"/storage/shared/data/2lep_df_forML_signal.hdf5\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "boring-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop(\"category\")\n",
    "y = df[\"isSignal\"]\n",
    "df.pop(\"isSignal\")\n",
    "X = df\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liable-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109683372, 19)\n",
      "(109683372,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-victim",
   "metadata": {},
   "source": [
    "### Data handling and preperations\n",
    "Before we train on the data, we need to scale it and split it into a validation and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surprised-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removed-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "included-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val= train_test_split(\n",
    "                X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-catalog",
   "metadata": {},
   "source": [
    "Now we need to separate the signal from the background in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecological-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_back = X_train[np.where(y_train == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-thumbnail",
   "metadata": {},
   "source": [
    "Then we perform a new split, such that we get a validation and training set for the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlike-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b_train, X_b_val= train_test_split(\n",
    "                X_back, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brilliant-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = np.shape(X_b_train)[1]\n",
    "number_of_rows = np.shape(X_b_train)[0]\n",
    "n_vali = np.shape(X_b_val)[0]\n",
    "random_indices = np.random.choice(number_of_rows, size=int(1e6), replace=False)\n",
    "\n",
    "test_indices = np.random.choice(n_vali, size=int(200000), replace=False)\n",
    "\n",
    "smaller_data = X_b_train[random_indices, :]\n",
    "small_vali = X_b_val[test_indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-medicaid",
   "metadata": {},
   "source": [
    "### Training\n",
    "Now we can train on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "genuine-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from gridsearch import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "greater-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gridautoencoder(X_b, X_back_test):\n",
    "    tuner = kt.Hyperband(\n",
    "        AE_model_builder,\n",
    "        objective=kt.Objective(\"val_mse\", direction=\"min\"),\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory=\"GridSearches\",\n",
    "        project_name=\"AE\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    tuner.search(X_b, X_b, epochs=50, batch_size=4000,\n",
    "                 validation_data=(X_back_test, X_back_test))\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    For Encoder: \\n \n",
    "    First layer has {best_hps.get('num_of_neurons0')} with activation {best_hps.get('0_act')} \\n\n",
    "    Second layer has {best_hps.get('num_of_neurons1')} with activation {best_hps.get('1_act')} \\n\n",
    "    \n",
    "    Latent layer has {best_hps.get(\"lat_num\")} with activation {best_hps.get('2_act')} \\n\n",
    "    \\n\n",
    "    For Decoder: \\n \n",
    "    First layer has {best_hps.get('num_of_neurons5')} with activation {best_hps.get('5_act')}\\n\n",
    "    Second layer has {best_hps.get('num_of_neurons6')} with activation {best_hps.get('6_act')}\\n\n",
    "    Third layer has activation {best_hps.get('7_act')}\\n\n",
    "    \\n\n",
    "    with learning rate = {best_hps.get('learning_rate')} and alpha = {best_hps.get('alpha')}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    state = True\n",
    "    while state == True:\n",
    "        answ = input(\"Do you want to save model? (y/n) \")\n",
    "        if answ == \"y\":\n",
    "            name = input(\"name: \")\n",
    "            tuner.hypermodel.build(best_hps).save(\n",
    "                f\"../tf_models/model_{name}.h5\")\n",
    "            state = False\n",
    "            print(\"Model saved\")\n",
    "        elif answ == \"n\":\n",
    "            state = False\n",
    "            print(\"Model not saved\")\n",
    "\n",
    "\n",
    "def AE_model_builder(hp):\n",
    "    \n",
    "\n",
    "    alpha_choice = hp.Choice(\"alpha\", values=[1., 0.5, 0.1, 0.05, 0.01])\n",
    "    #get_custom_objects().update({\"leakyrelu\": tf.keras.layers.LeakyReLU(alpha=alpha_choice)})\n",
    "    activations = {\n",
    "        \"relu\": tf.nn.relu,\n",
    "        \"tanh\": tf.nn.tanh,\n",
    "        \"leakyrelu\": lambda x: tf.nn.leaky_relu(x, alpha=alpha_choice),\n",
    "    }\n",
    "    inputs = tf.keras.layers.Input(shape=data_shape, name=\"encoder_input\")\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons0\", min_value=13, max_value=17, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"0_act\", [\"relu\", \"tanh\", \"leakyrelu\"])))(inputs)\n",
    "    x1 = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons1\", min_value=7, max_value=12, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"1_act\", [\"relu\", \"tanh\", \"leakyrelu\"]))\n",
    "    )(x)\n",
    "    val = hp.Int(\"lat_num\", min_value=1, max_value=6, step=1)\n",
    "    x2 = tf.keras.layers.Dense(\n",
    "        units=val, activation=activations.get(hp.Choice(\n",
    "            \"2_act\", [\"relu\", \"tanh\", \"leakyrelu\"]))\n",
    "    )(x1)\n",
    "    encoder = tf.keras.Model(inputs, x2, name=\"encoder\")\n",
    "\n",
    "    latent_input = tf.keras.layers.Input(shape=val, name=\"decoder_input\")\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons5\", min_value=7, max_value=12, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"5_act\", [\"relu\", \"tanh\", \"leakyrelu\"]))\n",
    "    )(latent_input)\n",
    "    x1 = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons6\", min_value=13, max_value=17, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"6_act\", [\"relu\", \"tanh\", \"leakyrelu\"]))\n",
    "    )(x)\n",
    "    output = tf.keras.layers.Dense(\n",
    "        data_shape, activation=activations.get(hp.Choice(\n",
    "            \"7_act\", [\"relu\", \"tanh\", \"leakyrelu\"]))\n",
    "    )(x1)\n",
    "    decoder = tf.keras.Model(latent_input, output, name=\"decoder\")\n",
    "\n",
    "    outputs = decoder(encoder(inputs))\n",
    "    AE_model = tf.keras.Model(inputs, outputs, name=\"AE_model\")\n",
    "\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[\n",
    "                                 9e-2, 9.5e-2, 1e-3, 1.5e-3])\n",
    "    optimizer = tf.keras.optimizers.Adam(hp_learning_rate)\n",
    "    AE_model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "\n",
    "    return AE_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "packed-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-pride",
   "metadata": {},
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "rocky-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 Complete [00h 00m 51s]\n",
      "val_mse: 0.34281668066978455\n",
      "\n",
      "Best val_mse So Far: 0.04355898126959801\n",
      "Total elapsed time: 00h 34m 09s\n",
      "\n",
      "Search: Running Trial #59\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.01              |0.1               |alpha\n",
      "14                |15                |num_of_neurons0\n",
      "relu              |relu              |0_act\n",
      "10                |7                 |num_of_neurons1\n",
      "tanh              |leakyrelu         |1_act\n",
      "6                 |4                 |lat_num\n",
      "tanh              |tanh              |2_act\n",
      "10                |11                |num_of_neurons5\n",
      "tanh              |tanh              |5_act\n",
      "17                |17                |num_of_neurons6\n",
      "tanh              |tanh              |6_act\n",
      "tanh              |leakyrelu         |7_act\n",
      "0.001             |0.095             |learning_rate\n",
      "6                 |50                |tuner/epochs\n",
      "0                 |17                |tuner/initial_epoch\n",
      "2                 |3                 |tuner/bracket\n",
      "0                 |3                 |tuner/round\n",
      "\n",
      "Epoch 1/6\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.4065 - mse: 0.4065 - val_loss: 0.2891 - val_mse: 0.2891\n",
      "Epoch 2/6\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 0.2504 - mse: 0.2504 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 3/6\n",
      " 65/250 [======>.......................] - ETA: 7s - loss: 0.2225 - mse: 0.2225"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    gridautoencoder(smaller_data, small_vali)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "developed-conclusion",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-66d2cda28da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgridautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmaller_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_vali\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/galaxy/jobs_directory/003/3118/working/jupyter/gridsearch.py\u001b[0m in \u001b[0;36mgridautoencoder\u001b[0;34m(X_b, X_back_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgridautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_back_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     tuner = kt.Hyperband(\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mAE_model_builder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_set\n",
    "from plot_set import plot_histo\n",
    "\n",
    "b = (err_val)#-np.min(err_val))/(np.max(err_val)-np.min(err_val))\n",
    "print(b)\n",
    "\n",
    "print(len(b))\n",
    "\n",
    "plot_histo(b, \"AE_histo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_model.save(\"ex_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-journal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
