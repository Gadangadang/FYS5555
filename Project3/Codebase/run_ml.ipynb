{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-property",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "impaired-composite",
   "metadata": {},
   "source": [
    "# ML test\n",
    "### Testing of reading in data and trying an auto encoder\n",
    "Remember to pip3 install keras-tuner to tune for the given session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "religious-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "seed = tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hired-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"/storage/shared/data/2lep_df_forML.hdf5\")\n",
    "df = pd.concat([df,pd.read_hdf(\"/storage/shared/data/2lep_df_forML_signal.hdf5\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "robust-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop(\"category\")\n",
    "y = df[\"isSignal\"]\n",
    "df.pop(\"isSignal\")\n",
    "X = df\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floppy-berkeley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109683372, 19)\n",
      "(109683372,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-conversation",
   "metadata": {},
   "source": [
    "### Data handling and preperations\n",
    "Before we train on the data, we need to scale it and split it into a validation and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regular-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verbal-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposite-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val= train_test_split(\n",
    "                X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-fraction",
   "metadata": {},
   "source": [
    "Now we need to separate the signal from the background in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crucial-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_back = X_train[np.where(y_train == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-validation",
   "metadata": {},
   "source": [
    "Then we perform a new split, such that we get a validation and training set for the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brave-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b_train, X_b_val= train_test_split(\n",
    "                X_back, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "parliamentary-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = np.shape(X_b_train)[1]\n",
    "number_of_rows = np.shape(X_b_train)[0]\n",
    "n_vali = np.shape(X_b_val)[0]\n",
    "random_indices = np.random.choice(number_of_rows, size=int(1e6), replace=False)\n",
    "\n",
    "test_indices = np.random.choice(n_vali, size=int(200000), replace=False)\n",
    "\n",
    "smaller_data = X_b_train[random_indices, :]\n",
    "small_vali = X_b_val[test_indices, :]\n",
    "\n",
    "\n",
    "test_indices_1 = np.random.choice(np.shape(X_val)[0], size=int(200000), replace=False)\n",
    "X_val = X_val[test_indices_1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-czech",
   "metadata": {},
   "source": [
    "### Training\n",
    "Now we can train on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "defensive-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from gridsearch import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "interstate-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gridautoencoder(X_b, X_back_test):\n",
    "    tuner = kt.Hyperband(\n",
    "        AE_model_builder,\n",
    "        objective=kt.Objective(\"val_mse\", direction=\"min\"),\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory=\"GridSearches\",\n",
    "        project_name=\"AE\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    tuner.search(X_b, X_b, epochs=50, batch_size=4000,\n",
    "                 validation_data=(X_back_test, X_back_test))\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    For Encoder: \\n \n",
    "    First layer has {best_hps.get('num_of_neurons0')} with activation {best_hps.get('0_act')} \\n\n",
    "    Second layer has {best_hps.get('num_of_neurons1')} with activation {best_hps.get('1_act')} \\n\n",
    "    \n",
    "    Latent layer has {best_hps.get(\"lat_num\")} with activation {best_hps.get('2_act')} \\n\n",
    "    \\n\n",
    "    For Decoder: \\n \n",
    "    First layer has {best_hps.get('num_of_neurons5')} with activation {best_hps.get('5_act')}\\n\n",
    "    Second layer has {best_hps.get('num_of_neurons6')} with activation {best_hps.get('6_act')}\\n\n",
    "    Third layer has activation {best_hps.get('7_act')}\\n\n",
    "    \\n\n",
    "    with learning rate = {best_hps.get('learning_rate')} and alpha = {best_hps.get('alpha')}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    state = True\n",
    "    while state == True:\n",
    "        answ = input(\"Do you want to save model? (y/n) \")\n",
    "        if answ == \"y\":\n",
    "            name = input(\"name: \")\n",
    "            tuner.hypermodel.build(best_hps).save(\n",
    "                f\"../tf_models/model_{name}.h5\")\n",
    "            state = False\n",
    "            print(\"Model saved\")\n",
    "        elif answ == \"n\":\n",
    "            state = False\n",
    "            print(\"Model not saved\")\n",
    "\n",
    "\n",
    "def AE_model_builder(hp):\n",
    "    \n",
    "\n",
    "    alpha_choice = hp.Choice(\"alpha\", values=[1., 0.5, 0.1, 0.05, 0.01])\n",
    "    #get_custom_objects().update({\"leakyrelu\": tf.keras.layers.LeakyReLU(alpha=alpha_choice)})\n",
    "    activations = {\n",
    "        \"relu\": tf.nn.relu,\n",
    "        \"tanh\": tf.nn.tanh,\n",
    "        \"leakyrelu\": lambda x: tf.nn.leaky_relu(x, alpha=alpha_choice),\n",
    "        \"linear\": tf.nn.linear\n",
    "    }\n",
    "    inputs = tf.keras.layers.Input(shape=data_shape, name=\"encoder_input\")\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons0\", min_value=13, max_value=17, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"0_act\", [\"relu\", \"tanh\", \"leakyrelu\"])))(inputs)\n",
    "    x1 = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons1\", min_value=7, max_value=12, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"1_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x)\n",
    "    val = hp.Int(\"lat_num\", min_value=1, max_value=6, step=1)\n",
    "    x2 = tf.keras.layers.Dense(\n",
    "        units=val, activation=activations.get(hp.Choice(\n",
    "            \"2_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x1)\n",
    "    encoder = tf.keras.Model(inputs, x2, name=\"encoder\")\n",
    "\n",
    "    latent_input = tf.keras.layers.Input(shape=val, name=\"decoder_input\")\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons5\", min_value=7, max_value=12, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"5_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(latent_input)\n",
    "    x1 = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons6\", min_value=13, max_value=17, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"6_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x)\n",
    "    output = tf.keras.layers.Dense(\n",
    "        data_shape, activation=activations.get(hp.Choice(\n",
    "            \"7_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x1)\n",
    "    decoder = tf.keras.Model(latent_input, output, name=\"decoder\")\n",
    "\n",
    "    outputs = decoder(encoder(inputs))\n",
    "    AE_model = tf.keras.Model(inputs, outputs, name=\"AE_model\")\n",
    "\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[\n",
    "                                 9e-2, 9.5e-2, 1e-3, 1.5e-3])\n",
    "    optimizer = tf.keras.optimizers.Adam(hp_learning_rate)\n",
    "    AE_model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "\n",
    "    return AE_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "injured-plymouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-fashion",
   "metadata": {},
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "plain-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "realistic-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 04m 22s]\n",
      "val_mse: 0.10679914057254791\n",
      "\n",
      "Best val_mse So Far: 0.022179190069437027\n",
      "Total elapsed time: 01h 47m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "    For Encoder: \n",
      " \n",
      "    First layer has 16 with activation leakyrelu \n",
      "\n",
      "    Second layer has 10 with activation leakyrelu \n",
      "\n",
      "    \n",
      "    Latent layer has 5 with activation tanh \n",
      "\n",
      "    \n",
      "\n",
      "    For Decoder: \n",
      " \n",
      "    First layer has 11 with activation tanh\n",
      "\n",
      "    Second layer has 14 with activation tanh\n",
      "\n",
      "    Third layer has activation leakyrelu\n",
      "\n",
      "    \n",
      "\n",
      "    with learning rate = 0.0015 and alpha = 1.0\n",
      "    \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to save model? (y/n)  y\n",
      "name:  prelim_ae_2lep_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    gridautoencoder(smaller_data, small_vali)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "equal-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypermodel = tf.keras.models.load_model(\"../tf_models/model_prelim_ae_2lep_data.h5\")\n",
    "inputs = tf.keras.layers.Input(shape=data_shape, name=\"encoder_input\")\n",
    "x = tf.keras.layers.Dense(units=16,activation=tf.keras.layers.LeakyReLU(alpha=1.))(inputs)\n",
    "x1 = tf.keras.layers.Dense(units=10,activation=tf.keras.layers.LeakyReLU(alpha=1.))(x)\n",
    "val = 5\n",
    "x2 = tf.keras.layers.Dense(units=val, activation=\"tanh\")(x1)\n",
    "encoder = tf.keras.Model(inputs, x2, name=\"encoder\")\n",
    "\n",
    "latent_input = tf.keras.layers.Input(shape=val, name=\"decoder_input\")\n",
    "x = tf.keras.layers.Dense(units=11,activation=\"tanh\")(latent_input)\n",
    "x1 = tf.keras.layers.Dense(units=14,activation=\"tanh\")(x)\n",
    "output = tf.keras.layers.Dense(data_shape, activation=tf.keras.layers.LeakyReLU(alpha=1.))(x1)\n",
    "decoder = tf.keras.Model(latent_input, output, name=\"decoder\")\n",
    "\n",
    "outputs = decoder(encoder(inputs))\n",
    "AE_model = tf.keras.Model(inputs, outputs, name=\"AE_model\")\n",
    "\n",
    "hp_learning_rate = 0.0015\n",
    "optimizer = tf.keras.optimizers.Adam(hp_learning_rate)\n",
    "AE_model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "social-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17104/17104 [==============================] - 323s 19ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 2/10\n",
      "17104/17104 [==============================] - 308s 18ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 3/10\n",
      "17104/17104 [==============================] - 305s 18ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4/10\n",
      "17104/17104 [==============================] - 286s 17ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 5/10\n",
      "17104/17104 [==============================] - 348s 20ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 6/10\n",
      "17104/17104 [==============================] - 340s 20ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 7/10\n",
      "17104/17104 [==============================] - 310s 18ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 8/10\n",
      "17104/17104 [==============================] - 325s 19ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 9/10\n",
      "17104/17104 [==============================] - 311s 18ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 10/10\n",
      "17104/17104 [==============================] - 317s 19ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0112 - val_mse: 0.0112\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    AE_model.fit(X_b_train, X_b_train, epochs=10, batch_size=4000, validation_data=(X_b_val, X_b_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "viral-confusion",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-0f2939ae746f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Calculate prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/software/easybuild/software/TensorFlow/2.5.0-fosscuda-2020b/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                                            batch_outputs)\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m               nest.map_structure_up_to(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                   \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                   \u001b[0;32mlambda\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/software/easybuild/software/TensorFlow/2.5.0-fosscuda-2020b/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \"\"\"\n\u001b[0;32m-> 1374\u001b[0;31m   return map_structure_with_tuple_paths_up_to(\n\u001b[0m\u001b[1;32m   1375\u001b[0m       \u001b[0mshallow_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Discards the path arg.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/software/easybuild/software/TensorFlow/2.5.0-fosscuda-2020b/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure_with_tuple_paths_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       path for path, _ in _yield_flat_up_to(shallow_tree, inputs[0], is_seq))\n\u001b[1;32m   1472\u001b[0m   results = [\n\u001b[0;32m-> 1473\u001b[0;31m       \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_path_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_value_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m   ]\n\u001b[1;32m   1475\u001b[0m   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,\n",
      "\u001b[0;32m/storage/software/easybuild/software/TensorFlow/2.5.0-fosscuda-2020b/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1462\u001b[0m   \u001b[0;31m# Flatten each input separately, apply the function to corresponding elements,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m   \u001b[0;31m# then repack based on the structure of the first input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m   flat_value_gen = (\n\u001b[0m\u001b[1;32m   1465\u001b[0m       flatten_up_to(  # pylint: disable=g-complex-comprehension\n\u001b[1;32m   1466\u001b[0m           \u001b[0mshallow_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import plot_set\n",
    "\n",
    "\n",
    "#Calculate prediction\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    pred_back = AE_model.predict(X_b_val)\n",
    "    print(\"Background done\")\n",
    "    pred_sig = AE_model.predict(X_val)\n",
    "    print(\"Signal done\")\n",
    "    \n",
    "recon_err_back = tf.keras.losses.msle(pred_back, X_b_val)\n",
    "recon_err_sig = tf.keras.losses.msle(pred_sig, X_val)\n",
    "\n",
    "b = recon_err_back/np.max(recon_err_back)\n",
    "b_s = recon_err_sig/np.max(recon_err_sig)\n",
    "\n",
    "binsize = 100\n",
    "plt.figure(num=0, dpi=80, facecolor='w', edgecolor='k')\n",
    "n_b, bins_b, patches_b = plt.hist(b, bins=binsize, histtype=\"stepfilled\", facecolor=\"b\",\n",
    "                                  label=\"Background\", density=True)\n",
    "\n",
    "n_b, bins_b, patches_b = plt.hist(b_s, bins=binsize, histtype=\"stepfilled\", facecolor=\"b\",\n",
    "                                  label=\"Background and signal\", density=True)\n",
    "\n",
    "plt.xlabel(\"Output\", fontsize=15)\n",
    "plt.ylabel(\"#Events\", fontsize=15)\n",
    "plt.title(\"Autoencoder output distribution\", fontsize=15, fontweight=\"bold\")\n",
    "plt.legend(fontsize=16, loc=\"lower right\")\n",
    "\n",
    "plt.savefig(\"AE_output.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-asthma",
   "metadata": {},
   "source": [
    "Now we implement testing of the data, and stacking of histograms with the reconstruction for the given background processes, a signal, and ATLAS data.\n",
    "\n",
    "Might have to implement ROOT histograms for stacking of histograms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-pierre",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-translator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-simple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-hardware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mounted-fairy",
   "metadata": {},
   "source": [
    "Here we plot the ROC curves for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-acrobat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
