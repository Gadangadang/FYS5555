{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "planned-pocket",
   "metadata": {},
   "source": [
    "# Deplyment of semi unsupervised learning on ATLAS OpenData\n",
    "### Testing of reading in data and trying an auto encoder\n",
    "Remember to pip3 install keras-tuner to tune for the given session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "annual-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "seed = tf.random.set_seed(1)\n",
    "#import ROOT as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "religious-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atlas = pd.read_hdf(\"/storage/shared/data/2lep_df_forML_data_fromRDF.hdf5\")\n",
    "df = pd.read_hdf(\"/storage/shared/data/2lep_df_forML_bkg_signal_fromRDF.hdf5\")\n",
    "\n",
    "#weights = pd.read_csv(\"weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "southeast-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 109683372 entries, 0 to 109683371\n",
      "Data columns (total 39 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   njet20                     int32  \n",
      " 1   njet60                     int32  \n",
      " 2   nbjet60                    int32  \n",
      " 3   nbjet70                    int32  \n",
      " 4   nbjet77                    int32  \n",
      " 5   nbjet85                    int32  \n",
      " 6   isOS                       int32  \n",
      " 7   isSF                       int32  \n",
      " 8   mll                        float32\n",
      " 9   mt2                        float32\n",
      " 10  met_et                     float32\n",
      " 11  met_phi                    float32\n",
      " 12  lep1_flav                  int32  \n",
      " 13  lep1_pt                    float32\n",
      " 14  lep1_eta                   float32\n",
      " 15  lep1_phi                   float32\n",
      " 16  lep1_E                     float32\n",
      " 17  lep1_ptcone30              float32\n",
      " 18  lep1_etcone20              float32\n",
      " 19  lep1_trackd0pvunbiased     float32\n",
      " 20  lep1_tracksigd0pvunbiased  float32\n",
      " 21  lep1_isTightID             float32\n",
      " 22  lep1_z0                    float32\n",
      " 23  lep2_flav                  int32  \n",
      " 24  lep2_pt                    float32\n",
      " 25  lep2_eta                   float32\n",
      " 26  lep2_phi                   float32\n",
      " 27  lep2_E                     float32\n",
      " 28  lep2_ptcone30              float32\n",
      " 29  lep2_etcone20              float32\n",
      " 30  lep2_trackd0pvunbiased     float32\n",
      " 31  lep2_tracksigd0pvunbiased  float32\n",
      " 32  lep2_isTightID             float32\n",
      " 33  lep2_z0                    float32\n",
      " 34  channelNumber              int32  \n",
      " 35  costhstar                  float32\n",
      " 36  weight                     float64\n",
      " 37  category                   object \n",
      " 38  physdescr                  object \n",
      "dtypes: float32(25), float64(1), int32(11), object(2)\n",
      "memory usage: 18.0+ GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11442336 entries, 0 to 11442335\n",
      "Data columns (total 37 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   njet20                     int32  \n",
      " 1   njet60                     int32  \n",
      " 2   nbjet60                    int32  \n",
      " 3   nbjet70                    int32  \n",
      " 4   nbjet77                    int32  \n",
      " 5   nbjet85                    int32  \n",
      " 6   isOS                       int32  \n",
      " 7   isSF                       int32  \n",
      " 8   mll                        float32\n",
      " 9   mt2                        float32\n",
      " 10  met_et                     float32\n",
      " 11  met_phi                    float32\n",
      " 12  lep1_flav                  int32  \n",
      " 13  lep1_pt                    float32\n",
      " 14  lep1_eta                   float32\n",
      " 15  lep1_phi                   float32\n",
      " 16  lep1_E                     float32\n",
      " 17  lep1_ptcone30              float32\n",
      " 18  lep1_etcone20              float32\n",
      " 19  lep1_trackd0pvunbiased     float32\n",
      " 20  lep1_tracksigd0pvunbiased  float32\n",
      " 21  lep1_isTightID             float32\n",
      " 22  lep1_z0                    float32\n",
      " 23  lep2_flav                  int32  \n",
      " 24  lep2_pt                    float32\n",
      " 25  lep2_eta                   float32\n",
      " 26  lep2_phi                   float32\n",
      " 27  lep2_E                     float32\n",
      " 28  lep2_ptcone30              float32\n",
      " 29  lep2_etcone20              float32\n",
      " 30  lep2_trackd0pvunbiased     float32\n",
      " 31  lep2_tracksigd0pvunbiased  float32\n",
      " 32  lep2_isTightID             float32\n",
      " 33  lep2_z0                    float32\n",
      " 34  channelNumber              int32  \n",
      " 35  costhstar                  float32\n",
      " 36  weight                     float64\n",
      "dtypes: float32(25), float64(1), int32(11)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df_atlas.info()\n",
    "#weights.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-prompt",
   "metadata": {},
   "source": [
    "### Adding more columns \n",
    "Because the dataset is lacking the \"isSignal\" and \"weight\" columns, we have to create them our self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "restricted-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Zjetsincl', 'Zjets', 'Diboson', 'Higgs', 'singleTop', 'topX',\n",
       "       'RS_G_ZZ', 'SUSYC1N2', 'Wjets', 'SUSYC1C1', 'dmV_Zll', 'ttbar',\n",
       "       'GG_ttn1', 'ZPrimett', 'Gee', 'SUSYSlepSlep', 'ZPrimeee',\n",
       "       'ZPrimemumu', 'Wjetsincl', 'Gmumu', 'TT_directTT'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rough-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ['ZPrimemumu', 'SUSYC1C1', 'RS_G_ZZ', 'SUSYSlepSlep', 'SUSYC1N2', 'ZPrimett', 'ZPrimeee', 'dmV_Zll', 'GG_ttn1', 'TT_directTT', 'Gee', 'Gmumu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "threatened-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "issignal = np.where(df[\"category\"].isin(signals)  , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "internal-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(isSignal=issignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "rocky-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>njet20</th>\n",
       "      <th>njet60</th>\n",
       "      <th>nbjet60</th>\n",
       "      <th>nbjet70</th>\n",
       "      <th>nbjet77</th>\n",
       "      <th>nbjet85</th>\n",
       "      <th>isOS</th>\n",
       "      <th>isSF</th>\n",
       "      <th>mll</th>\n",
       "      <th>mt2</th>\n",
       "      <th>...</th>\n",
       "      <th>lep2_trackd0pvunbiased</th>\n",
       "      <th>lep2_tracksigd0pvunbiased</th>\n",
       "      <th>lep2_isTightID</th>\n",
       "      <th>lep2_z0</th>\n",
       "      <th>channelNumber</th>\n",
       "      <th>costhstar</th>\n",
       "      <th>weight</th>\n",
       "      <th>category</th>\n",
       "      <th>physdescr</th>\n",
       "      <th>isSignal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83241.078125</td>\n",
       "      <td>203008.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022843</td>\n",
       "      <td>0.767920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>361106</td>\n",
       "      <td>0.113907</td>\n",
       "      <td>0.127318</td>\n",
       "      <td>Zjetsincl</td>\n",
       "      <td>Zee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91189.015625</td>\n",
       "      <td>115910.992188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001654</td>\n",
       "      <td>0.100329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.136329</td>\n",
       "      <td>361106</td>\n",
       "      <td>0.864449</td>\n",
       "      <td>0.114645</td>\n",
       "      <td>Zjetsincl</td>\n",
       "      <td>Zee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   njet20  njet60  nbjet60  nbjet70  nbjet77  nbjet85  isOS  isSF  \\\n",
       "0       0       0        0        0        0        0     1     1   \n",
       "1       1       0        0        0        0        0     1     1   \n",
       "\n",
       "            mll            mt2  ...  lep2_trackd0pvunbiased  \\\n",
       "0  83241.078125  203008.812500  ...               -0.022843   \n",
       "1  91189.015625  115910.992188  ...               -0.001654   \n",
       "\n",
       "   lep2_tracksigd0pvunbiased  lep2_isTightID   lep2_z0  channelNumber  \\\n",
       "0                   0.767920             1.0  0.000382         361106   \n",
       "1                   0.100329             1.0 -0.136329         361106   \n",
       "\n",
       "   costhstar    weight   category  physdescr  isSignal  \n",
       "0   0.113907  0.127318  Zjetsincl        Zee         0  \n",
       "1   0.864449  0.114645  Zjetsincl        Zee         0  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "studied-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>njet20</th>\n",
       "      <th>njet60</th>\n",
       "      <th>nbjet60</th>\n",
       "      <th>nbjet70</th>\n",
       "      <th>nbjet77</th>\n",
       "      <th>nbjet85</th>\n",
       "      <th>isOS</th>\n",
       "      <th>isSF</th>\n",
       "      <th>mll</th>\n",
       "      <th>mt2</th>\n",
       "      <th>...</th>\n",
       "      <th>lep2_E</th>\n",
       "      <th>lep2_ptcone30</th>\n",
       "      <th>lep2_etcone20</th>\n",
       "      <th>lep2_trackd0pvunbiased</th>\n",
       "      <th>lep2_tracksigd0pvunbiased</th>\n",
       "      <th>lep2_isTightID</th>\n",
       "      <th>lep2_z0</th>\n",
       "      <th>channelNumber</th>\n",
       "      <th>costhstar</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12510.837891</td>\n",
       "      <td>57409.433594</td>\n",
       "      <td>...</td>\n",
       "      <td>10032.247070</td>\n",
       "      <td>1196.712769</td>\n",
       "      <td>-92.074127</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>0.044793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.024559</td>\n",
       "      <td>300800</td>\n",
       "      <td>0.131353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91430.445312</td>\n",
       "      <td>192062.109375</td>\n",
       "      <td>...</td>\n",
       "      <td>192062.109375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-174.402069</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.373168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.064178</td>\n",
       "      <td>300800</td>\n",
       "      <td>0.323297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   njet20  njet60  nbjet60  nbjet70  nbjet77  nbjet85  isOS  isSF  \\\n",
       "0       1       0        0        0        0        0     1     1   \n",
       "1       1       0        0        0        0        0     1     1   \n",
       "\n",
       "            mll            mt2  ...         lep2_E  lep2_ptcone30  \\\n",
       "0  12510.837891   57409.433594  ...   10032.247070    1196.712769   \n",
       "1  91430.445312  192062.109375  ...  192062.109375       0.000000   \n",
       "\n",
       "   lep2_etcone20  lep2_trackd0pvunbiased  lep2_tracksigd0pvunbiased  \\\n",
       "0     -92.074127               -0.000793                   0.044793   \n",
       "1    -174.402069                0.003242                   0.373168   \n",
       "\n",
       "   lep2_isTightID   lep2_z0  channelNumber  costhstar  weight  \n",
       "0             1.0 -0.024559         300800   0.131353     1.0  \n",
       "1             1.0 -0.064178         300800   0.323297     1.0  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atlas.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-humidity",
   "metadata": {},
   "source": [
    "### Data separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "settled-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/software/easybuild/software/SciPy-bundle/2020.11-fosscuda-2020b/lib/python3.8/site-packages/pandas/core/frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "categories = df[\"category\"]\n",
    "\n",
    "background_categories = df[df[\"isSignal\"] == 0][\"category\"].unique()\n",
    "signal_df = df[df['category'] == 'SUSYC1C1']\n",
    "\n",
    "background_df = df[df[\"isSignal\"] == 0]\n",
    "\n",
    "columns_to_drop = [\"category\", \"isSignal\", \"physdescr\"]\n",
    "\n",
    "\n",
    "signal_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "background_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "signal_mc = signal_df#.to_numpy()\n",
    "background_mc = background_df#.to_numpy()\n",
    "\n",
    "data = df_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "instant-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106898318, 37)\n",
      "(135127, 37)\n",
      "(11442336, 37)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(background_mc))\n",
    "print(np.shape(signal_mc))\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-cartoon",
   "metadata": {},
   "source": [
    "### Data handling and preperations\n",
    "Before we train on the data, we need to scale it and split it into a validation and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cathedral-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "handmade-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split background\n",
    "X_b_train, X_b_val = train_test_split(background_mc, test_size=0.2, random_state=seed)\n",
    "# Split signal\n",
    "#X_s_train, X_s_test = train_test_split(signal_mc, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-mandate",
   "metadata": {},
   "source": [
    "Now, combine samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "interpreted-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train_weights = X_b_train[\"weight\"]\n",
    "b_val_weights = X_b_val[\"weight\"]\n",
    "s_test_weights = signal_mc[\"weight\"]\n",
    "\n",
    "data_weights = data[\"weight\"]\n",
    "\n",
    "X_b_train.pop(\"weight\")\n",
    "X_b_val.pop(\"weight\")\n",
    "signal_mc.pop(\"weight\")\n",
    "data.pop(\"weight\")\n",
    "\n",
    "\n",
    "X_s_test = signal_mc\n",
    "\n",
    "\n",
    "X_test = np.concatenate((X_b_val,X_s_test),0)\n",
    "\n",
    "y_b_val = np.zeros(X_b_val.shape[0])                                                                                                                                                                                                                                                   \n",
    "y_s_test = np.ones(X_s_test.shape[0])      \n",
    "y_test = np.concatenate((y_b_val,y_s_test),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "animal-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85518654, 36)\n",
      "(135127, 36)\n",
      "(11442336, 36)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_b_train))\n",
    "print(np.shape(signal_mc))\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-cliff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "enclosed-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ae = StandardScaler()#MinMaxScaler()\n",
    "X_b_train = scaler_ae.fit_transform(X_b_train)                                                                                                                                                                                                                        \n",
    "X_b_val= scaler_ae.transform(X_b_val)                                                                                                                                                                                                                                 \n",
    "X_s_test = scaler_ae.transform(X_s_test)\n",
    "data = scaler_ae.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "comic-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = np.shape(X_b_train)[1]\n",
    "number_of_rows = np.shape(X_b_train)[0]\n",
    "n_vali = np.shape(X_b_val)[0]\n",
    "\n",
    "random_indices_b = np.random.choice(number_of_rows, size=int(1e6), replace=False)\n",
    "test_indices_b = np.random.choice(n_vali, size=int(200000), replace=False)\n",
    "\n",
    "smaller_data = X_b_train[random_indices_b, :]\n",
    "small_vali = X_b_val[test_indices_b, :]\n",
    "\n",
    "\n",
    "test_indices_sb = np.random.choice(np.shape(X_test)[0], size=int(200000), replace=False)\n",
    "X_small_test = X_test[test_indices_sb, :]\n",
    "\n",
    "in_and_out = X_b_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-bradley",
   "metadata": {},
   "source": [
    "### Training\n",
    "Now we can train on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "placed-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gridautoencoder(X_b, X_back_test):\n",
    "    tuner = kt.Hyperband(\n",
    "        AE_model_builder,\n",
    "        objective=kt.Objective(\"val_mse\", direction=\"min\"),\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory=\"GridSearches\",\n",
    "        project_name=\"AE\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    tuner.search(X_b, X_b, epochs=50, batch_size=512,\n",
    "                 validation_data=(X_back_test, X_back_test))\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    For Encoder: \\n \n",
    "    First layer has {best_hps.get('num_of_neurons0')} with activation {best_hps.get('0_act')} \\n\n",
    "    Second layer has {best_hps.get('num_of_neurons1')} with activation {best_hps.get('1_act')} \\n\n",
    "    \n",
    "    Latent layer has {best_hps.get(\"lat_num\")} with activation {best_hps.get('2_act')} \\n\n",
    "    \\n\n",
    "    For Decoder: \\n \n",
    "    First layer has {best_hps.get('num_of_neurons5')} with activation {best_hps.get('5_act')}\\n\n",
    "    Second layer has {best_hps.get('num_of_neurons6')} with activation {best_hps.get('6_act')}\\n\n",
    "    Third layer has activation {best_hps.get('7_act')}\\n\n",
    "    \\n\n",
    "    with learning rate = {best_hps.get('learning_rate')} and alpha = {best_hps.get('alpha')}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    state = True\n",
    "    while state == True:\n",
    "        answ = input(\"Do you want to save model? (y/n) \")\n",
    "        if answ == \"y\":\n",
    "            name = input(\"name: \")\n",
    "            tuner.hypermodel.build(best_hps).save(\n",
    "                f\"../tf_models/model_{name}.h5\")\n",
    "            state = False\n",
    "            print(\"Model saved\")\n",
    "        elif answ == \"n\":\n",
    "            state = False\n",
    "            print(\"Model not saved\")\n",
    "\n",
    "\n",
    "def AE_model_builder(hp):\n",
    "    \n",
    "\n",
    "    alpha_choice = hp.Choice(\"alpha\", values=[1., 0.5, 0.1, 0.05, 0.01])\n",
    "    #get_custom_objects().update({\"leakyrelu\": tf.keras.layers.LeakyReLU(alpha=alpha_choice)})\n",
    "    activations = {\n",
    "        \"relu\": tf.nn.relu,\n",
    "        \"tanh\": tf.nn.tanh,\n",
    "        \"leakyrelu\": lambda x: tf.nn.leaky_relu(x, alpha=alpha_choice),\n",
    "        \"linear\": tf.keras.activations.linear\n",
    "    }\n",
    "    inputs = tf.keras.layers.Input(shape=data_shape, name=\"encoder_input\")\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons0\", min_value=16, max_value=data_shape-1, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"0_act\", [\"relu\", \"tanh\", \"leakyrelu\"])))(inputs)\n",
    "    x1 = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons1\", min_value=7, max_value=15, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"1_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x)\n",
    "    val = hp.Int(\"lat_num\", min_value=1, max_value=6, step=1)\n",
    "    x2 = tf.keras.layers.Dense(\n",
    "        units=val, activation=activations.get(hp.Choice(\n",
    "            \"2_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x1)\n",
    "    encoder = tf.keras.Model(inputs, x2, name=\"encoder\")\n",
    "\n",
    "    latent_input = tf.keras.layers.Input(shape=val, name=\"decoder_input\")\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons5\", min_value=7, max_value=15, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"5_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(latent_input)\n",
    "    x1 = tf.keras.layers.Dense(\n",
    "        units=hp.Int(\"num_of_neurons6\", min_value=16, max_value=data_shape-1, step=1),\n",
    "        activation=activations.get(hp.Choice(\n",
    "            \"6_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x)\n",
    "    output = tf.keras.layers.Dense(\n",
    "        data_shape, activation=activations.get(hp.Choice(\n",
    "            \"7_act\", [\"relu\", \"tanh\", \"leakyrelu\",\"linear\"]))\n",
    "    )(x1)\n",
    "    decoder = tf.keras.Model(latent_input, output, name=\"decoder\")\n",
    "\n",
    "    outputs = decoder(encoder(inputs))\n",
    "    AE_model = tf.keras.Model(inputs, outputs, name=\"AE_model\")\n",
    "\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[\n",
    "                                 9e-2, 9.5e-2, 1e-3, 1.5e-3])\n",
    "    optimizer = tf.keras.optimizers.Adam(hp_learning_rate)\n",
    "    #optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    AE_model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "\n",
    "    return AE_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    gridautoencoder(smaller_data, small_vali)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-science",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-permission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "brief-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypermodel = tf.keras.models.load_model(\"../tf_models/model_prelim_ae_2lep_data.h5\")\n",
    "inputs = tf.keras.layers.Input(shape=data_shape, name=\"encoder_input\")\n",
    "x = tf.keras.layers.Dense(units=16,activation=tf.keras.layers.LeakyReLU(alpha=0.01))(inputs)\n",
    "x1 = tf.keras.layers.Dense(units=6,activation=\"tanh\")(x)\n",
    "val = 6\n",
    "x2 = tf.keras.layers.Dense(units=val, activation=tf.keras.layers.LeakyReLU(alpha=0.01))(x1)\n",
    "encoder = tf.keras.Model(inputs, x2, name=\"encoder\")\n",
    "\n",
    "latent_input = tf.keras.layers.Input(shape=val, name=\"decoder_input\")\n",
    "x = tf.keras.layers.Dense(units=10,activation=\"linear\")(latent_input)\n",
    "x1 = tf.keras.layers.Dense(units=14,activation=tf.keras.layers.LeakyReLU(alpha=0.01))(x)\n",
    "output = tf.keras.layers.Dense(data_shape, activation=\"linear\")(x1)\n",
    "decoder = tf.keras.Model(latent_input, output, name=\"decoder\")\n",
    "\n",
    "outputs = decoder(encoder(inputs))\n",
    "AE_model = tf.keras.Model(inputs, outputs, name=\"AE_model\")\n",
    "\n",
    "hp_learning_rate = 0.0015\n",
    "optimizer = tf.keras.optimizers.Adam(hp_learning_rate)\n",
    "AE_model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "wrong-sewing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "21380/21380 [==============================] - 285s 13ms/step - loss: 0.4549 - mse: 0.4549 - val_loss: 0.4203 - val_mse: 0.4203\n",
      "Epoch 2/2\n",
      "21380/21380 [==============================] - 449s 21ms/step - loss: 0.4210 - mse: 0.4210 - val_loss: 0.4093 - val_mse: 0.4093\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    AE_model.fit(X_b_train, X_b_train, epochs=2, batch_size=4000, validation_data=(X_b_val, X_b_val), use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate prediction\n",
    "#with tf.device(\"/CPU:0\"):\n",
    "pred_back = AE_model.predict(X_b_val)\n",
    "print(\"Background done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sig = AE_model.predict(X_s_test)\n",
    "print(\"Signal done\")\n",
    "#pred_data = AE_model.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = AE_model.predict(data)\n",
    "print(\"ATLAS data done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-minneapolis",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "Now we implement testing of the data, and stacking of histograms with the reconstruction <br> for the given background processes, a signal, and ATLAS data. <br>\n",
    "<br>\n",
    "First for background\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import reconstructionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_err_back = reconstructionError(pred_back, X_b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-screen",
   "metadata": {},
   "source": [
    "Then signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_err_sig = reconstructionError(pred_sig, X_s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-basics",
   "metadata": {},
   "source": [
    "An then for actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recon_data = tf.keras.losses.msle(pred_data, X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(recon_err_back), np.min(recon_err_back), np.max(recon_err_back))\n",
    "print(np.shape(recon_err_sig), np.min(recon_err_sig), np.max(recon_err_sig))\n",
    "#print(np.shape(recon_data), np.min(recon_data), np.max(recon_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-processor",
   "metadata": {},
   "source": [
    "Then  plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = recon_err_back#/np.max(recon_err_back)\n",
    "b_s = recon_err_sig#/np.max(recon_err_sig)\n",
    "#norm_recon_data = recon_data/np.max(recon_data)\n",
    "\n",
    "histo_data = [b_s,b]#, norm_recon_data])\n",
    "weight_histo = [s_test_weights,b_val_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_set\n",
    "plt.rcParams[\"figure.figsize\"] = (12,9)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "n_bins= 200\n",
    "colors = [\"green\", \"red\"]\n",
    "labels= [\"Signal\", \"Background\"]\n",
    "ax.hist(histo_data, n_bins, density=True, stacked=True, histtype='bar', color=colors, label=labels, weights=(s_test_weights, b_val_weights))\n",
    "ax.legend(prop={'size': 10})\n",
    "ax.set_title('Reconstruction error histogram with background and signal')\n",
    "ax.set_xlabel('log10 Reconstruction error')\n",
    "ax.set_ylabel('#Events')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"b_s_recon.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-sweet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abroad-blogger",
   "metadata": {},
   "source": [
    "Here we plot the ROC curves for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "Y_b = np.zeros(X_b_val.shape[0]).reshape(X_b_val.shape[0],1);\n",
    "Y_s = np.ones(X_s_test.shape[0]).reshape(X_s_test.shape[0],1);\n",
    "Y_ROC = np.concatenate((Y_s, Y_b),0);\n",
    "\n",
    "sample_weight = np.concatenate((s_test_weights, b_val_weights),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rec_errors_ROC = np.concatenate((recon_err_sig,recon_err_back),0)\n",
    "\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_ROC, rec_errors_ROC, sample_weight = sample_weight, pos_label=1)\n",
    "ae_auc = roc_auc_score(Y_ROC, rec_errors_ROC)\n",
    "figRocAE, axRocAE = plt.subplots()\n",
    "figRocAE.set_size_inches(12,12)\n",
    "axRocAE.plot(fpr, tpr, label='ROC curve')\n",
    "axRocAE.plot([0, 1], [0, 1], 'k--')\n",
    "axRocAE.set_xlim([0.0, 1.0])\n",
    "axRocAE.set_ylim([0.0, 1.05])\n",
    "axRocAE.set_xlabel('False Anomaly Rate')\n",
    "axRocAE.set_ylabel('True Anomaly Rate')\n",
    "axRocAE.text(0.4,0.2,\"AUC = %.4f\" % ae_auc,fontsize=15)\n",
    "axRocAE.set_title(\"Autoencoder ROC\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"b_s_roc_curve.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-performer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-words",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-looking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
